{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('binary.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0        0  380  3.61       0       0       1       0\n",
       "1        1  660  3.67       0       0       1       0\n",
       "2        1  800  4.00       1       0       0       0\n",
       "3        1  640  3.19       0       0       0       1\n",
       "4        0  520  2.93       0       0       0       1\n",
       "..     ...  ...   ...     ...     ...     ...     ...\n",
       "395      0  620  4.00       0       1       0       0\n",
       "396      0  560  3.04       0       0       1       0\n",
       "397      0  460  2.63       0       1       0       0\n",
       "398      0  700  3.65       0       1       0       0\n",
       "399      0  600  3.89       0       0       1       0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make dummy variables for rank\n",
    "data = pd.concat([df, pd.get_dummies(df['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.798011</td>\n",
       "      <td>0.578348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>0.736008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.837832</td>\n",
       "      <td>1.603135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.452749</td>\n",
       "      <td>-0.525269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.586063</td>\n",
       "      <td>-1.208461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0.279614</td>\n",
       "      <td>1.603135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.239793</td>\n",
       "      <td>-0.919418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.105469</td>\n",
       "      <td>-1.996759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0.972155</td>\n",
       "      <td>0.683454</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>1.314093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0        0 -1.798011  0.578348       0       0       1       0\n",
       "1        1  0.625884  0.736008       0       0       1       0\n",
       "2        1  1.837832  1.603135       1       0       0       0\n",
       "3        1  0.452749 -0.525269       0       0       0       1\n",
       "4        0 -0.586063 -1.208461       0       0       0       1\n",
       "..     ...       ...       ...     ...     ...     ...     ...\n",
       "395      0  0.279614  1.603135       0       1       0       0\n",
       "396      0 -0.239793 -0.919418       0       0       1       0\n",
       "397      0 -1.105469 -1.996759       0       1       0       0\n",
       "398      0  0.972155  0.683454       0       1       0       0\n",
       "399      0  0.106478  1.314093       0       0       1       0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standarize features\n",
    "for field in ['gre','gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data.loc[:,field] = (data[field]-mean)/std\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.066657</td>\n",
       "      <td>0.289305</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>1.445476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1.837832</td>\n",
       "      <td>1.603135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>1.318426</td>\n",
       "      <td>-0.131120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.066657</td>\n",
       "      <td>-1.208461</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>0.279614</td>\n",
       "      <td>0.946220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.239793</td>\n",
       "      <td>-1.155908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.412928</td>\n",
       "      <td>-0.577822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>1.603135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.412928</td>\n",
       "      <td>-0.288780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
       "209      0 -0.066657  0.289305       0       1       0       0\n",
       "280      0  0.625884  1.445476       0       1       0       0\n",
       "33       1  1.837832  1.603135       0       0       1       0\n",
       "210      0  1.318426 -0.131120       0       0       0       1\n",
       "93       0 -0.066657 -1.208461       0       1       0       0\n",
       "..     ...       ...       ...     ...     ...     ...     ...\n",
       "393      1  0.279614  0.946220       0       1       0       0\n",
       "134      0 -0.239793 -1.155908       0       1       0       0\n",
       "306      1 -0.412928 -0.577822       1       0       0       0\n",
       "383      0  0.625884  1.603135       1       0       0       0\n",
       "319      0 -0.412928 -0.288780       1       0       0       0\n",
       "\n",
       "[360 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(data.index, size=int( len(data)*0.9 ), replace=False)\n",
    "data, test_data = data.iloc[sample], data.drop(sample)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2641790041019977\n",
      "Train loss:  0.26417472965566063\n",
      "Train loss:  0.2641615079155366\n",
      "Train loss:  0.2641464912820564\n",
      "Train loss:  0.2641118978332227\n",
      "Train loss:  0.2640819558759907\n",
      "Train loss:  0.2640389477455856\n",
      "Train loss:  0.2639992186913413\n",
      "Train loss:  0.2639523544144303\n",
      "Train loss:  0.26390337673866077\n",
      "Train loss:  0.26385862095385526\n",
      "Train loss:  0.2638136788575853\n",
      "Train loss:  0.2637595003534591\n",
      "Train loss:  0.263699523752723\n",
      "Train loss:  0.263629770674233\n",
      "Train loss:  0.2635674465165958\n",
      "Train loss:  0.26351355923565273\n",
      "Train loss:  0.26345568038568995\n",
      "Train loss:  0.2633906904336899\n",
      "Train loss:  0.26331492747685115\n",
      "Train loss:  0.26323057195985733\n",
      "Train loss:  0.2631401308535169\n",
      "Train loss:  0.26304876738561583\n",
      "Train loss:  0.26295043761983944\n",
      "Train loss:  0.2628475037614048\n",
      "Train loss:  0.26273316551882686\n",
      "Train loss:  0.26262412702786925\n",
      "Train loss:  0.2625162044997055\n",
      "Train loss:  0.2624199980577825\n",
      "Train loss:  0.2623223604336845\n",
      "Train loss:  0.2622280752361219\n",
      "Train loss:  0.2621301775960817\n",
      "Train loss:  0.26201509449154775\n",
      "Train loss:  0.2618872205797161\n",
      "Train loss:  0.2617461137690624\n",
      "Train loss:  0.26161407390768804\n",
      "Train loss:  0.2614793026670326\n",
      "Train loss:  0.26134762497117275\n",
      "Train loss:  0.2612103538412276\n",
      "Train loss:  0.2610737506690933\n",
      "Train loss:  0.26094311291545724\n",
      "Train loss:  0.2608067572083974\n",
      "Train loss:  0.2606650767456882\n",
      "Train loss:  0.26051967368869083\n",
      "Train loss:  0.26035155634637375\n",
      "Train loss:  0.26017646385000515\n",
      "Train loss:  0.26001168754413356\n",
      "Train loss:  0.2598495621623265\n",
      "Train loss:  0.2596759151453212\n",
      "Train loss:  0.25950530202746\n",
      "Train loss:  0.259340796644842\n",
      "Train loss:  0.2591698744032331\n",
      "Train loss:  0.258996171324834\n",
      "Train loss:  0.2588279385800928\n",
      "Train loss:  0.2586579482967933\n",
      "Train loss:  0.2585074628493992\n",
      "Train loss:  0.2583555077422622\n",
      "Train loss:  0.25820090729176237\n",
      "Train loss:  0.2580479140984152\n",
      "Train loss:  0.2578954388674924\n",
      "Train loss:  0.2577466999444633\n",
      "Train loss:  0.25758480436191705\n",
      "Train loss:  0.25741804877618524\n",
      "Train loss:  0.2572471613447721\n",
      "Train loss:  0.25707443700133015\n",
      "Train loss:  0.2568971349886675\n",
      "Train loss:  0.2567304404484776\n",
      "Train loss:  0.25656800189590706\n",
      "Train loss:  0.25640378321650265\n",
      "Train loss:  0.2562408739619583\n",
      "Train loss:  0.25607149700647897\n",
      "Train loss:  0.2559026289692941\n",
      "Train loss:  0.25573969988399975\n",
      "Train loss:  0.2555833839357972\n",
      "Train loss:  0.25541503228118834\n",
      "Train loss:  0.2552375759406858\n",
      "Train loss:  0.25505270737152563\n",
      "Train loss:  0.25486792665912844\n",
      "Train loss:  0.25466263167626035\n",
      "Train loss:  0.25444451462456075\n",
      "Train loss:  0.25423388387777507\n",
      "Train loss:  0.2540210452253486\n",
      "Train loss:  0.2538035273883044\n",
      "Train loss:  0.2535815651231845\n",
      "Train loss:  0.2533475863368587\n",
      "Train loss:  0.2531137942108501\n",
      "Train loss:  0.2528788057489812\n",
      "Train loss:  0.25264722576733706\n",
      "Train loss:  0.252409807275617\n",
      "Train loss:  0.25217088600773996\n",
      "Train loss:  0.25192375004689205\n",
      "Train loss:  0.2516749104713755\n",
      "Train loss:  0.25142582168370214\n",
      "Train loss:  0.25117261433565696\n",
      "Train loss:  0.25092023883312403\n",
      "Train loss:  0.25066669857151436\n",
      "Train loss:  0.2504151200930368\n",
      "Train loss:  0.25015912464911805\n",
      "Train loss:  0.2498989796502166\n",
      "Train loss:  0.24964144808012156\n",
      "Train loss:  0.24937575142406054\n",
      "Train loss:  0.24910277829180028\n",
      "Train loss:  0.24883141318208613\n",
      "Train loss:  0.24855848387226281\n",
      "Train loss:  0.24828262906578932\n",
      "Train loss:  0.24799891159778226\n",
      "Train loss:  0.2477119272007645\n",
      "Train loss:  0.2474270834343705\n",
      "Train loss:  0.2471475914941708\n",
      "Train loss:  0.24685338514903327\n",
      "Train loss:  0.24654357700822002\n",
      "Train loss:  0.24622650811177588\n",
      "Train loss:  0.24590533725696345\n",
      "Train loss:  0.24558708847619803\n",
      "Train loss:  0.24526091006286863\n",
      "Train loss:  0.24494316135039435\n",
      "Train loss:  0.2446224366328956\n",
      "Train loss:  0.24429893369300462\n",
      "Train loss:  0.2439743825261851\n",
      "Train loss:  0.24364970579985967\n",
      "Train loss:  0.24332398479469583\n",
      "Train loss:  0.24299481724431327\n",
      "Train loss:  0.24266285235827184\n",
      "Train loss:  0.2423297365920164\n",
      "Train loss:  0.24200300770568248\n",
      "Train loss:  0.2416837527716605\n",
      "Train loss:  0.2413618864299363\n",
      "Train loss:  0.24104008097549628\n",
      "Train loss:  0.24071704425372564\n",
      "Train loss:  0.24039252736262434\n",
      "Train loss:  0.24006370330211033\n",
      "Train loss:  0.23973597845928607\n",
      "Train loss:  0.23940537703289438\n",
      "Train loss:  0.23908351985893514\n",
      "Train loss:  0.23876163413111454\n",
      "Train loss:  0.23844650595223063\n",
      "Train loss:  0.23813802094386116\n",
      "Train loss:  0.23783073537997287\n",
      "Train loss:  0.23752381717894816\n",
      "Train loss:  0.23721329265352895\n",
      "Train loss:  0.23690327808326078\n",
      "Train loss:  0.2365947954652045\n",
      "Train loss:  0.23627102364054187\n",
      "Train loss:  0.23595820762218295\n",
      "Train loss:  0.23563941591333082\n",
      "Train loss:  0.2353264447073903\n",
      "Train loss:  0.2350087289543082\n",
      "Train loss:  0.2346931270889242\n",
      "Train loss:  0.23438176640758962\n",
      "Train loss:  0.2340697780639027\n",
      "Train loss:  0.2337625490192843\n",
      "Train loss:  0.2334546515580306\n",
      "Train loss:  0.23315695502511058\n",
      "Train loss:  0.2328621717647334\n",
      "Train loss:  0.2325648279564004\n",
      "Train loss:  0.23226658428352384\n",
      "Train loss:  0.23197066309517247\n",
      "Train loss:  0.23166703663960955\n",
      "Train loss:  0.23136847743361508\n",
      "Train loss:  0.23106402184466476\n",
      "Train loss:  0.2307596859584795\n",
      "Train loss:  0.230453945290002\n",
      "Train loss:  0.23015262531190628\n",
      "Train loss:  0.22985456059405363\n",
      "Train loss:  0.22954989068719592\n",
      "Train loss:  0.22924929654127624\n",
      "Train loss:  0.2289532867567348\n",
      "Train loss:  0.22865203435222717\n",
      "Train loss:  0.22834744683281605\n",
      "Train loss:  0.22804288590490632\n",
      "Train loss:  0.22773237068190744\n",
      "Train loss:  0.2274201748461883\n",
      "Train loss:  0.22710759612253592\n",
      "Train loss:  0.22679373563225672\n",
      "Train loss:  0.22647930521302415\n",
      "Train loss:  0.2261581462350364\n",
      "Train loss:  0.22583825553997638\n",
      "Train loss:  0.22551823075141103\n",
      "Train loss:  0.22520234134379402\n",
      "Train loss:  0.22488230379372773\n",
      "Train loss:  0.224561714351052\n",
      "Train loss:  0.22424131546596995\n",
      "Train loss:  0.2239203518786017\n",
      "Train loss:  0.22359767752680565\n",
      "Train loss:  0.2232754196546514\n",
      "Train loss:  0.22295391246941137\n",
      "Train loss:  0.22263169298380986\n",
      "Train loss:  0.22231482322269475\n",
      "Train loss:  0.22200557593558198\n",
      "Train loss:  0.22169655686120976\n",
      "Train loss:  0.22138891488871368\n",
      "Train loss:  0.2210827633244621\n",
      "Train loss:  0.2207827201177281\n",
      "Train loss:  0.22048054829171906\n",
      "Train loss:  0.22017954505153187\n",
      "Train loss:  0.2198804686892742\n",
      "Train loss:  0.2195798647932512\n",
      "Train loss:  0.21928283331147752\n",
      "Train loss:  0.21898689052160508\n",
      "Train loss:  0.21869443663140484\n",
      "Train loss:  0.21840483773570152\n",
      "Train loss:  0.21811971441120429\n",
      "Train loss:  0.2178356515953857\n",
      "Train loss:  0.21754935908151957\n",
      "Train loss:  0.2172618705723939\n",
      "Train loss:  0.21697678705444526\n",
      "Train loss:  0.2166977254079136\n",
      "Train loss:  0.2164232855751628\n",
      "Train loss:  0.21615121616171987\n",
      "Train loss:  0.21587257779390306\n",
      "Train loss:  0.21559631323539008\n",
      "Train loss:  0.2153230006426308\n",
      "Train loss:  0.21505284493614088\n",
      "Train loss:  0.21478780995419752\n",
      "Train loss:  0.21451961523533047\n",
      "Train loss:  0.21424930587167704\n",
      "Train loss:  0.21398487418796128\n",
      "Train loss:  0.21372278246771761\n",
      "Train loss:  0.21346852549592493\n",
      "Train loss:  0.21322013820907412\n",
      "Train loss:  0.21296796563718973\n",
      "Train loss:  0.21271599560967497\n",
      "Train loss:  0.21246783492159702\n",
      "Train loss:  0.21222119442912413\n",
      "Train loss:  0.21197619388901173\n",
      "Train loss:  0.2117338235986977\n",
      "Train loss:  0.21149366414229853\n",
      "Train loss:  0.21125979538898815\n",
      "Train loss:  0.2110296648069809\n",
      "Train loss:  0.21080123064487993\n",
      "Train loss:  0.21057584418814293\n",
      "Train loss:  0.2103551500221505\n",
      "Train loss:  0.2101394512171668\n",
      "Train loss:  0.20992683772136214\n",
      "Train loss:  0.20971624775094194\n",
      "Train loss:  0.2095044965334377\n",
      "Train loss:  0.20928598901785303\n",
      "Train loss:  0.20906725008938054\n",
      "Train loss:  0.20884874782151513\n",
      "Train loss:  0.20863537307001095\n",
      "Train loss:  0.20842243323698856\n",
      "Train loss:  0.20820955335356234\n",
      "Train loss:  0.20799608424838045\n",
      "Train loss:  0.20778491295890944\n",
      "Train loss:  0.20757733553464577\n",
      "Train loss:  0.20737286502717037\n",
      "Train loss:  0.20717018263148587\n",
      "Train loss:  0.2069704083133513\n",
      "Train loss:  0.20677351766648996\n",
      "Train loss:  0.20657891961819916\n",
      "Train loss:  0.2063871085240483\n",
      "Train loss:  0.2061972973386975\n",
      "Train loss:  0.20600952631495592\n",
      "Train loss:  0.2058269344048093\n",
      "Train loss:  0.20564350916624025\n",
      "Train loss:  0.20546307985302958\n",
      "Train loss:  0.20528604816848087\n",
      "Train loss:  0.20511157395432494\n",
      "Train loss:  0.20494636280121495\n",
      "Train loss:  0.204784611191864\n",
      "Train loss:  0.20462577956022798\n",
      "Train loss:  0.2044704072206301\n",
      "Train loss:  0.20431851135637627\n",
      "Train loss:  0.20417364798342158\n",
      "Train loss:  0.20403243417642986\n",
      "Train loss:  0.203894688356068\n",
      "Train loss:  0.20375978249242088\n",
      "Train loss:  0.2036284162826074\n",
      "Train loss:  0.20350071034059308\n",
      "Train loss:  0.2033752319036074\n",
      "Train loss:  0.20325254021188652\n",
      "Train loss:  0.2031325708492372\n",
      "Train loss:  0.20301627643749345\n",
      "Train loss:  0.20290328120429857\n",
      "Train loss:  0.20279270331133398\n",
      "Train loss:  0.20268599803121476\n",
      "Train loss:  0.20258352112418712\n",
      "Train loss:  0.20248337598968102\n",
      "Train loss:  0.20238896490570507\n",
      "Train loss:  0.202297351208338\n",
      "Train loss:  0.202207713773271\n",
      "Train loss:  0.20212123032815862\n",
      "Train loss:  0.2020374113613356\n",
      "Train loss:  0.20195654644410302\n",
      "Train loss:  0.20187940862072287\n",
      "Train loss:  0.20180964985546546\n",
      "Train loss:  0.20174235689054948\n",
      "Train loss:  0.20167718895250303\n",
      "Train loss:  0.20161377156373606\n",
      "Train loss:  0.20155707771689962\n",
      "Train loss:  0.20150254149936206\n",
      "Train loss:  0.20144996852806893\n",
      "Train loss:  0.20140008453485017\n",
      "Train loss:  0.201352853231776\n",
      "Train loss:  0.20130765297923672\n",
      "Train loss:  0.20126567074589216\n",
      "Train loss:  0.20122697951156157\n",
      "Train loss:  0.20119214545428082\n",
      "Train loss:  0.20115958320905822\n",
      "Train loss:  0.20113013578153516\n",
      "Train loss:  0.20110223181292836\n",
      "Train loss:  0.20107552939805376\n",
      "Train loss:  0.20104901657471477\n",
      "Train loss:  0.2010263502576339\n",
      "Train loss:  0.20100736693945606\n",
      "Train loss:  0.20099159668012195\n",
      "Train loss:  0.20097907244236965\n",
      "Train loss:  0.20097038893207733\n",
      "Train loss:  0.20096606380083834\n",
      "Train loss:  0.20096554563028673\n",
      "Train loss:  0.20096671984696068  Warning - Loss Increasing\n",
      "Train loss:  0.20097029883705736  Warning - Loss Increasing\n",
      "Train loss:  0.20097622570690213  Warning - Loss Increasing\n",
      "Train loss:  0.2009846184897834  Warning - Loss Increasing\n",
      "Train loss:  0.20099557874417198  Warning - Loss Increasing\n",
      "Train loss:  0.2010067404020527  Warning - Loss Increasing\n",
      "Train loss:  0.20101955411509043  Warning - Loss Increasing\n",
      "Train loss:  0.2010358640337628  Warning - Loss Increasing\n",
      "Train loss:  0.20105180340920156  Warning - Loss Increasing\n",
      "Train loss:  0.20106962968061864  Warning - Loss Increasing\n",
      "Train loss:  0.20108968770371105  Warning - Loss Increasing\n",
      "Train loss:  0.20111192678497072  Warning - Loss Increasing\n",
      "Train loss:  0.2011374002498609  Warning - Loss Increasing\n",
      "Train loss:  0.20116463412851474  Warning - Loss Increasing\n",
      "Train loss:  0.20119149754630372  Warning - Loss Increasing\n",
      "Train loss:  0.2012200383126543  Warning - Loss Increasing\n",
      "Train loss:  0.2012449340310147  Warning - Loss Increasing\n",
      "Train loss:  0.2012714335190374  Warning - Loss Increasing\n",
      "Train loss:  0.20129878508820487  Warning - Loss Increasing\n",
      "Train loss:  0.201329775536184  Warning - Loss Increasing\n",
      "Train loss:  0.2013625456215865  Warning - Loss Increasing\n",
      "Train loss:  0.20139810080678447  Warning - Loss Increasing\n",
      "Train loss:  0.20143470069918834  Warning - Loss Increasing\n",
      "Train loss:  0.20147277474143965  Warning - Loss Increasing\n",
      "Train loss:  0.20151542339981232  Warning - Loss Increasing\n",
      "Train loss:  0.20155741244273834  Warning - Loss Increasing\n",
      "Train loss:  0.20159800569448183  Warning - Loss Increasing\n",
      "Train loss:  0.20163799396783166  Warning - Loss Increasing\n",
      "Train loss:  0.20167922761939888  Warning - Loss Increasing\n",
      "Train loss:  0.20172148442057825  Warning - Loss Increasing\n",
      "Train loss:  0.20176091245758762  Warning - Loss Increasing\n",
      "Train loss:  0.20179894882807756  Warning - Loss Increasing\n",
      "Train loss:  0.20183557828702972  Warning - Loss Increasing\n",
      "Train loss:  0.20187261638894347  Warning - Loss Increasing\n",
      "Train loss:  0.2019097118315711  Warning - Loss Increasing\n",
      "Train loss:  0.20194874355689474  Warning - Loss Increasing\n",
      "Train loss:  0.20198897922536116  Warning - Loss Increasing\n",
      "Train loss:  0.2020294316826847  Warning - Loss Increasing\n",
      "Train loss:  0.20207132626880941  Warning - Loss Increasing\n",
      "Train loss:  0.20211585736924706  Warning - Loss Increasing\n",
      "Train loss:  0.20216362747711447  Warning - Loss Increasing\n",
      "Train loss:  0.2022134738298886  Warning - Loss Increasing\n",
      "Train loss:  0.2022650306875592  Warning - Loss Increasing\n",
      "Train loss:  0.20231738258319645  Warning - Loss Increasing\n",
      "Train loss:  0.2023719882761545  Warning - Loss Increasing\n",
      "Train loss:  0.20242350134123474  Warning - Loss Increasing\n",
      "Train loss:  0.20247669054592007  Warning - Loss Increasing\n",
      "Train loss:  0.20253284475225578  Warning - Loss Increasing\n",
      "Train loss:  0.202592697780637  Warning - Loss Increasing\n",
      "Train loss:  0.20265263357747265  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522781942  Warning - Loss Increasing\n",
      "Train loss:  0.21795000906945172\n",
      "Train loss:  0.2179400729654934\n",
      "Train loss:  0.2179264901457714\n",
      "Train loss:  0.21791360816121666\n",
      "Train loss:  0.21790039900504393\n",
      "Train loss:  0.21788725639160897\n",
      "Train loss:  0.21787937752812755\n",
      "Train loss:  0.21787165468776715\n",
      "Train loss:  0.21786551938873064\n",
      "Train loss:  0.21784564714300522\n",
      "Train loss:  0.21782508021265856\n",
      "Train loss:  0.2178047141877544\n",
      "Train loss:  0.21778451238149638\n",
      "Train loss:  0.21776382591583426\n",
      "Train loss:  0.2177416214472148\n",
      "Train loss:  0.2177191155941763\n",
      "Train loss:  0.21769077222673186\n",
      "Train loss:  0.2176624213565377\n",
      "Train loss:  0.21763569263996113\n",
      "Train loss:  0.21761368568724848\n",
      "Train loss:  0.2175918998901247\n",
      "Train loss:  0.21757508924382082\n",
      "Train loss:  0.21755846263063472\n",
      "Train loss:  0.21754203042676348\n",
      "Train loss:  0.2175257851673229\n",
      "Train loss:  0.21749471754928942\n",
      "Train loss:  0.21747328484108588\n",
      "Train loss:  0.2174494936420649\n",
      "Train loss:  0.21743021093526976\n",
      "Train loss:  0.21739882900665622\n",
      "Train loss:  0.217367597359498\n",
      "Train loss:  0.21733685589417087\n",
      "Train loss:  0.2173061654382909\n",
      "Train loss:  0.21727600525316174\n",
      "Train loss:  0.21724149089864978\n",
      "Train loss:  0.21720837281884492\n",
      "Train loss:  0.21717425319766098\n",
      "Train loss:  0.21713437894718426\n",
      "Train loss:  0.217102947615825\n",
      "Train loss:  0.21707169177969507\n",
      "Train loss:  0.21704777025846345\n",
      "Train loss:  0.2170239482827051\n",
      "Train loss:  0.21700074976363998\n",
      "Train loss:  0.21697780740242747\n",
      "Train loss:  0.216954682821862\n",
      "Train loss:  0.21692149761726578\n",
      "Train loss:  0.2168877429732586\n",
      "Train loss:  0.21685412433367424\n",
      "Train loss:  0.2168256089895014\n",
      "Train loss:  0.2167989787202009\n",
      "Train loss:  0.21677309251093876\n",
      "Train loss:  0.21675031973143707\n",
      "Train loss:  0.21671583161753294\n",
      "Train loss:  0.2166769639212499\n",
      "Train loss:  0.21663595367528804\n",
      "Train loss:  0.21658225718206658\n",
      "Train loss:  0.21652485187315712\n",
      "Train loss:  0.21646672214907017\n",
      "Train loss:  0.21641387272567622\n",
      "Train loss:  0.216345857312182\n",
      "Train loss:  0.2162788001039283\n",
      "Train loss:  0.2162109944150111\n",
      "Train loss:  0.21614653108840162\n",
      "Train loss:  0.21608130870354622\n",
      "Train loss:  0.21600964848938156\n",
      "Train loss:  0.21593632136942745\n",
      "Train loss:  0.21586889219566793\n",
      "Train loss:  0.21580411678166508\n",
      "Train loss:  0.21572995830538974\n",
      "Train loss:  0.21565604185541087\n",
      "Train loss:  0.2155704948722408\n",
      "Train loss:  0.21548970950419516\n",
      "Train loss:  0.21540671168783743\n",
      "Train loss:  0.21532349700929446\n",
      "Train loss:  0.2152362618225915\n",
      "Train loss:  0.2151493217013063\n",
      "Train loss:  0.21504919251984572\n",
      "Train loss:  0.21494955430767512\n",
      "Train loss:  0.21485014742368247\n",
      "Train loss:  0.21475115665273523\n",
      "Train loss:  0.21463832217147327\n",
      "Train loss:  0.2145264894113943\n",
      "Train loss:  0.2144143651178984\n",
      "Train loss:  0.21430328207523613\n",
      "Train loss:  0.21420263222116043\n",
      "Train loss:  0.2140962294218737\n",
      "Train loss:  0.2139976947437744\n",
      "Train loss:  0.2138994407379064\n",
      "Train loss:  0.21378866828146775\n",
      "Train loss:  0.21367823220569251\n",
      "Train loss:  0.2135700119427633\n",
      "Train loss:  0.21346275316075894\n",
      "Train loss:  0.21335601257698736\n",
      "Train loss:  0.21324523040351095\n",
      "Train loss:  0.2131348955344554\n",
      "Train loss:  0.2130259520492391\n",
      "Train loss:  0.2129071455816286\n",
      "Train loss:  0.21278496049363024\n",
      "Train loss:  0.212647677697035\n",
      "Train loss:  0.2125115233475237\n",
      "Train loss:  0.2123758478300609\n",
      "Train loss:  0.21222476690552053\n",
      "Train loss:  0.2120667845454385\n",
      "Train loss:  0.21190937892366185\n",
      "Train loss:  0.21175312450779687\n",
      "Train loss:  0.21159928060244085\n",
      "Train loss:  0.21143280117998128\n",
      "Train loss:  0.21126830404428776\n",
      "Train loss:  0.21110555023789748\n",
      "Train loss:  0.21094452990215382\n",
      "Train loss:  0.21078449139278968\n",
      "Train loss:  0.21061659238326788\n",
      "Train loss:  0.21045420979656726\n",
      "Train loss:  0.2102934804055526\n",
      "Train loss:  0.2101336421116557\n",
      "Train loss:  0.20997641371931774\n",
      "Train loss:  0.20982031721160493\n",
      "Train loss:  0.20966526267649202\n",
      "Train loss:  0.20951143671709932\n",
      "Train loss:  0.20935657598114357\n",
      "Train loss:  0.20920366919178296\n",
      "Train loss:  0.20905196527252073\n",
      "Train loss:  0.20889760200849664\n",
      "Train loss:  0.2087503236997707\n",
      "Train loss:  0.20860609657976772\n",
      "Train loss:  0.20846251781056266\n",
      "Train loss:  0.2083222434745321\n",
      "Train loss:  0.2081749004032442\n",
      "Train loss:  0.20801361707114863\n",
      "Train loss:  0.2078480130594026\n",
      "Train loss:  0.20768434481698408\n",
      "Train loss:  0.2075228779887639\n",
      "Train loss:  0.20736318086517638\n",
      "Train loss:  0.20720533314662945\n",
      "Train loss:  0.20705104614137057\n",
      "Train loss:  0.20690364198910333\n",
      "Train loss:  0.20675805707355124\n",
      "Train loss:  0.20661680861700987\n",
      "Train loss:  0.20647661241770277\n",
      "Train loss:  0.20633913270575058\n",
      "Train loss:  0.2062047177232984\n",
      "Train loss:  0.20606996225075488\n",
      "Train loss:  0.2059349638427699\n",
      "Train loss:  0.20580171303161285\n",
      "Train loss:  0.20566613584177063\n",
      "Train loss:  0.20553251101387207\n",
      "Train loss:  0.20540084213103854\n",
      "Train loss:  0.20526425702246295\n",
      "Train loss:  0.20513044351341633\n",
      "Train loss:  0.20499483340531777\n",
      "Train loss:  0.20486151299730967\n",
      "Train loss:  0.20472802160158396\n",
      "Train loss:  0.20459768376478715\n",
      "Train loss:  0.20445832140935438\n",
      "Train loss:  0.20431969712763293\n",
      "Train loss:  0.20418321747649193\n",
      "Train loss:  0.2040499446189159\n",
      "Train loss:  0.20391559228176478\n",
      "Train loss:  0.20377939555203123\n",
      "Train loss:  0.20364644644793062\n",
      "Train loss:  0.2035169479939558\n",
      "Train loss:  0.20339228925517652\n",
      "Train loss:  0.20327076020034515\n",
      "Train loss:  0.20314931420024765\n",
      "Train loss:  0.20303513606522344\n",
      "Train loss:  0.2029273895912665\n",
      "Train loss:  0.20282322819406506\n",
      "Train loss:  0.20272231967042634\n",
      "Train loss:  0.20262520665275147\n",
      "Train loss:  0.20252347401700835\n",
      "Train loss:  0.20241991689343297\n",
      "Train loss:  0.20232040336706766\n",
      "Train loss:  0.202224436407197\n",
      "Train loss:  0.20213254281668552\n",
      "Train loss:  0.20204375053583085\n",
      "Train loss:  0.2019596992974977\n",
      "Train loss:  0.20187981556506834\n",
      "Train loss:  0.20180267485606188\n",
      "Train loss:  0.2017295549850066\n",
      "Train loss:  0.20166081505656946\n",
      "Train loss:  0.20159635833297146\n",
      "Train loss:  0.20153628837986848\n",
      "Train loss:  0.20147809714239173\n",
      "Train loss:  0.20142359176624033\n",
      "Train loss:  0.20137392591001696\n",
      "Train loss:  0.2013291465565122\n",
      "Train loss:  0.20128804235914113\n",
      "Train loss:  0.2012545746679459\n",
      "Train loss:  0.20122595997474665\n",
      "Train loss:  0.20120178693344198\n",
      "Train loss:  0.20118253955755921\n",
      "Train loss:  0.20116766400744818\n",
      "Train loss:  0.20115720609752893\n",
      "Train loss:  0.2011509447668816\n",
      "Train loss:  0.20114880368851631\n",
      "Train loss:  0.20115069343639808  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003740071  Warning - Loss Increasing\n",
      "Train loss:  0.2011606006761904  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247299011  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674167166  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755354748  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801600154  Warning - Loss Increasing\n",
      "Train loss:  0.2012330497752949  Warning - Loss Increasing\n",
      "Train loss:  0.2012590232622394  Warning - Loss Increasing\n",
      "Train loss:  0.20128891233628401  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974512065  Warning - Loss Increasing\n",
      "Train loss:  0.2013582760942924  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944260812  Warning - Loss Increasing\n",
      "Train loss:  0.2014462994784143  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977353713  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631510729  Warning - Loss Increasing\n",
      "Train loss:  0.20162136982235812  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137287865  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785319092  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436528252  Warning - Loss Increasing\n",
      "Train loss:  0.20192359121479175  Warning - Loss Increasing\n",
      "Train loss:  0.2020149362918889  Warning - Loss Increasing\n",
      "Train loss:  0.20211402576479895  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107099296  Warning - Loss Increasing\n",
      "Train loss:  0.2023249052788637  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541766533  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121904104  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338464392  Warning - Loss Increasing\n",
      "Train loss:  0.202812984000978  Warning - Loss Increasing\n",
      "Train loss:  0.2029492825398086  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556806304  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871938202  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262225222  Warning - Loss Increasing\n",
      "Train loss:  0.20354405145432947  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291054874  Warning - Loss Increasing\n",
      "Train loss:  0.2038683941332696  Warning - Loss Increasing\n",
      "Train loss:  0.20403936794927485  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275664212  Warning - Loss Increasing\n",
      "Train loss:  0.20438974297096257  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007839952  Warning - Loss Increasing\n",
      "Train loss:  0.20475810799858477  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755600005  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908439462  Warning - Loss Increasing\n",
      "Train loss:  0.20532712653470186  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938074283  Warning - Loss Increasing\n",
      "Train loss:  0.20570977665599754  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182214925  Warning - Loss Increasing\n",
      "Train loss:  0.20611168928789908  Warning - Loss Increasing\n",
      "Train loss:  0.20631549471379934  Warning - Loss Increasing\n",
      "Train loss:  0.20652283574107425  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305456588  Warning - Loss Increasing\n",
      "Train loss:  0.2069530628491214  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531123176  Warning - Loss Increasing\n",
      "Train loss:  0.20739652220869567  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149349008  Warning - Loss Increasing\n",
      "Train loss:  0.20784428452775985  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850805544  Warning - Loss Increasing\n",
      "Train loss:  0.2082946058109877  Warning - Loss Increasing\n",
      "Train loss:  0.20852293871359123  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567375445  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494288404  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792238632  Warning - Loss Increasing\n",
      "Train loss:  0.2094784373171481  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934131065  Warning - Loss Increasing\n",
      "Train loss:  0.20998060442049646  Warning - Loss Increasing\n",
      "Train loss:  0.21022864089653603  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922904078  Warning - Loss Increasing\n",
      "Train loss:  0.2107215278334443  Warning - Loss Increasing\n",
      "Train loss:  0.21096847394408946  Warning - Loss Increasing\n",
      "Train loss:  0.21121927946288213  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600176076  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825273177  Warning - Loss Increasing\n",
      "Train loss:  0.2119674216737884  Warning - Loss Increasing\n",
      "Train loss:  0.21222180238220298  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753449297  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103828988  Warning - Loss Increasing\n",
      "Train loss:  0.21298884143671815  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359669577  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839430612  Warning - Loss Increasing\n",
      "Train loss:  0.21376749749735593  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745893493  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043712256  Warning - Loss Increasing\n",
      "Train loss:  0.21458067533039468  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332792917  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526589634  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025157576  Warning - Loss Increasing\n",
      "Train loss:  0.21569532939126213  Warning - Loss Increasing\n",
      "Train loss:  0.2159764844084077  Warning - Loss Increasing\n",
      "Train loss:  0.21626274383813257  Warning - Loss Increasing\n",
      "Train loss:  0.2165630320803723  Warning - Loss Increasing\n",
      "Train loss:  0.21686664198225505  Warning - Loss Increasing\n",
      "Train loss:  0.21717097212211614  Warning - Loss Increasing\n",
      "Train loss:  0.21747740758856215  Warning - Loss Increasing\n",
      "Train loss:  0.2177899541486309  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588232474  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220751361  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509250633  Warning - Loss Increasing\n",
      "Train loss:  0.2190575585209479  Warning - Loss Increasing\n",
      "Train loss:  0.21937892784596025  Warning - Loss Increasing\n",
      "Train loss:  0.21970535092195895  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293603033  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755947282  Warning - Loss Increasing\n",
      "Train loss:  0.22069646844913618  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361855127  Warning - Loss Increasing\n",
      "Train loss:  0.22137377971035427  Warning - Loss Increasing\n",
      "Train loss:  0.221705147056293  Warning - Loss Increasing\n",
      "Train loss:  0.2220319039194354  Warning - Loss Increasing\n",
      "Train loss:  0.22236278241008378  Warning - Loss Increasing\n",
      "Train loss:  0.2226971765753106  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468583672  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544446023  Warning - Loss Increasing\n",
      "Train loss:  0.2237129941118312  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674412937  Warning - Loss Increasing\n",
      "Train loss:  0.22440658526640272  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539890298  Warning - Loss Increasing\n",
      "Train loss:  0.2250608415939486  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915079964  Warning - Loss Increasing\n",
      "Train loss:  0.225678171513793  Warning - Loss Increasing\n",
      "Train loss:  0.2259714471084598  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331756548  Warning - Loss Increasing\n",
      "Train loss:  0.22650637332283782  Warning - Loss Increasing\n",
      "Train loss:  0.22677594699697196  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808838251  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170898223  Warning - Loss Increasing\n",
      "Train loss:  0.22753955367574277  Warning - Loss Increasing\n",
      "Train loss:  0.22778534258098548  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206370074  Warning - Loss Increasing\n",
      "Train loss:  0.2282831509625233  Warning - Loss Increasing\n",
      "Train loss:  0.22852510757791988  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226959534  Warning - Loss Increasing\n",
      "Train loss:  0.2289817080775073  Warning - Loss Increasing\n",
      "Train loss:  0.22919700654001265  Warning - Loss Increasing\n",
      "Train loss:  0.22941594393059295  Warning - Loss Increasing\n",
      "Train loss:  0.22963801483531768  Warning - Loss Increasing\n",
      "Train loss:  0.2298596963973885  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986453454  Warning - Loss Increasing\n",
      "Train loss:  0.23031452336611413  Warning - Loss Increasing\n",
      "Train loss:  0.23054049458333511  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280729035  Warning - Loss Increasing\n",
      "Train loss:  0.23099850533782332  Warning - Loss Increasing\n",
      "Train loss:  0.23122183859839443  Warning - Loss Increasing\n",
      "Train loss:  0.23143844928068122  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407682813  Warning - Loss Increasing\n",
      "Train loss:  0.23186772913033912  Warning - Loss Increasing\n",
      "Train loss:  0.23207162752704255  Warning - Loss Increasing\n",
      "Train loss:  0.23225331467047772  Warning - Loss Increasing\n",
      "Train loss:  0.2324267135031836  Warning - Loss Increasing\n",
      "Train loss:  0.23258559504474438  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036963279  Warning - Loss Increasing\n",
      "Train loss:  0.2328949342147687  Warning - Loss Increasing\n",
      "Train loss:  0.23304697345080683  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504966056  Warning - Loss Increasing\n",
      "Train loss:  0.23333680909049204  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743919387  Warning - Loss Increasing\n",
      "Train loss:  0.23365432350264592  Warning - Loss Increasing\n",
      "Train loss:  0.23383397738836317  Warning - Loss Increasing\n",
      "Train loss:  0.23401783921273933  Warning - Loss Increasing\n",
      "Train loss:  0.23419922432431226  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172946317  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409902765  Warning - Loss Increasing\n",
      "Train loss:  0.23471662438319324  Warning - Loss Increasing\n",
      "Train loss:  0.23488704190274798  Warning - Loss Increasing\n",
      "Train loss:  0.23507234590721443  Warning - Loss Increasing\n",
      "Train loss:  0.235251917684705  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035728\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.21790039899964506\n",
      "Train loss:  0.2178872563862179\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.2178655193833612\n",
      "Train loss:  0.2178456471376433\n",
      "Train loss:  0.2178250802073044\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.217784512376157\n",
      "Train loss:  0.2177638259105022\n",
      "Train loss:  0.21774162144189022\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.21757508923854432\n",
      "Train loss:  0.21755846262536555\n",
      "Train loss:  0.21754203042150141\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683205\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.2173675973542881\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.21724149089347122\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.21717425319250172\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.21707169177456448\n",
      "Train loss:  0.21704777025334038\n",
      "Train loss:  0.21702394827758986\n",
      "Train loss:  0.21700074975853378\n",
      "Train loss:  0.21697780739732891\n",
      "Train loss:  0.2169546828167714\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818694\n",
      "Train loss:  0.2168541243286119\n",
      "Train loss:  0.21682560898444844\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590487\n",
      "Train loss:  0.21675031972641234\n",
      "Train loss:  0.21671583161251726\n",
      "Train loss:  0.21667696391624416\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.2165822571770795\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410304\n",
      "Train loss:  0.2164138727207209\n",
      "Train loss:  0.21634585730723843\n",
      "Train loss:  0.2162788000989978\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449883\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681688\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.21565604185058776\n",
      "Train loss:  0.2155704948674316\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305323\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.21504919251511295\n",
      "Train loss:  0.21494955430295526\n",
      "Train loss:  0.21485014741897557\n",
      "Train loss:  0.21475115664803998\n",
      "Train loss:  0.21463832216679013\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059393\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916974\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688892\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.21357001193821143\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.21335601257246306\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995787\n",
      "Train loss:  0.21302595204475464\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.21278496048917456\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.2120667845410926\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.2117531245035223\n",
      "Train loss:  0.2115992805982025\n",
      "Train loss:  0.21143280117577964\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376842\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924954\n",
      "Train loss:  0.21045420979258675\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775098\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.20951143671334724\n",
      "Train loss:  0.20935657597743046\n",
      "Train loss:  0.20920366918810884\n",
      "Train loss:  0.20905196526888545\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624762\n",
      "Train loss:  0.20846251780707983\n",
      "Train loss:  0.2083222434710865\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.208013617067781\n",
      "Train loss:  0.2078480130560766\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551972\n",
      "Train loss:  0.2073631808619736\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.2069036419860217\n",
      "Train loss:  0.20675805707050918\n",
      "Train loss:  0.20661680861400664\n",
      "Train loss:  0.20647661241473905\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.2059349638399639\n",
      "Train loss:  0.20580171302884734\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839593\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.2049948334027982\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.20472802159914663\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700862\n",
      "Train loss:  0.20431969712533665\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322367\n",
      "Train loss:  0.2032707601984398\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.20303513606341347\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.20282322819234583\n",
      "Train loss:  0.2027223196687522\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542464\n",
      "Train loss:  0.20241991689189606\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575274\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447896\n",
      "Train loss:  0.20195969929619098\n",
      "Train loss:  0.20187981556380558\n",
      "Train loss:  0.20180267485484263\n",
      "Train loss:  0.20172955498383066\n",
      "Train loss:  0.20166081505543643\n",
      "Train loss:  0.2015963583318805\n",
      "Train loss:  0.2015362883788187\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713167\n",
      "Train loss:  0.2012259599739659\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.20118253955684232\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687052\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791305\n",
      "Train loss:  0.2011506934358215  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685013  Warning - Loss Increasing\n",
      "Train loss:  0.2011606006756656  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.2012590232618565  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477923  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396945  Warning - Loss Increasing\n",
      "Train loss:  0.2013993494423039  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812898  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327076  Warning - Loss Increasing\n",
      "Train loss:  0.20155816315082417  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266246  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.20192359121461828  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172704  Warning - Loss Increasing\n",
      "Train loss:  0.20211402576464862  Warning - Loss Increasing\n",
      "Train loss:  0.2022165410708531  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.20309235568053582  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.20354405145423296  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044957  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652558  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708383  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826727  Warning - Loss Increasing\n",
      "Train loss:  0.20475810799844463  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423508  Warning - Loss Increasing\n",
      "Train loss:  0.20532712653453078  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.20570977665579795  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.20611168928766194  Warning - Loss Increasing\n",
      "Train loss:  0.20631549471354257  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.2069530628488008  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088823  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.20784428452734022  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.2082946058105163  Warning - Loss Increasing\n",
      "Train loss:  0.20852293871309316  Warning - Loss Increasing\n",
      "Train loss:  0.2087556156732287  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180256  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653337  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981758  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.2104771592282952  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.21096847394327173  Warning - Loss Increasing\n",
      "Train loss:  0.21121927946202515  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086397  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281094  Warning - Loss Increasing\n",
      "Train loss:  0.21222180238118385  Warning - Loss Increasing\n",
      "Train loss:  0.21247797534387033  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.21298884143557595  Warning - Loss Increasing\n",
      "Train loss:  0.2132461035955102  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307632  Warning - Loss Increasing\n",
      "Train loss:  0.21376749749608107  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898445  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647534  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440075  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003808  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678244  Warning - Loss Increasing\n",
      "Train loss:  0.21626274383646202  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.21686664198049085  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.21747740758670117  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672006  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036392  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550566  Warning - Loss Increasing\n",
      "Train loss:  0.21874035092300764  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884384  Warning - Loss Increasing\n",
      "Train loss:  0.21937892784380758  Warning - Loss Increasing\n",
      "Train loss:  0.21970535091975654  Warning - Loss Increasing\n",
      "Train loss:  0.2200322829337792  Warning - Loss Increasing\n",
      "Train loss:  0.2203631275571727  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.2210333236161527  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.22170514705379116  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.2223627824074775  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.22337165444183485  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.2240578567412523  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591642  Warning - Loss Increasing\n",
      "Train loss:  0.2250608415909106  Warning - Loss Increasing\n",
      "Train loss:  0.22537059150490935  Warning - Loss Increasing\n",
      "Train loss:  0.22567817151065622  Warning - Loss Increasing\n",
      "Train loss:  0.2259714471052755  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.2265063733195597  Warning - Loss Increasing\n",
      "Train loss:  0.22677594699364667  Warning - Loss Increasing\n",
      "Train loss:  0.2270379980850095  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556238  Warning - Loss Increasing\n",
      "Train loss:  0.22753955367227713  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747304  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891777  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.228761952265895  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.2291970065362176  Warning - Loss Increasing\n",
      "Train loss:  0.22941594392674886  Warning - Loss Increasing\n",
      "Train loss:  0.22963801483142465  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344575  Warning - Loss Increasing\n",
      "Train loss:  0.2300841098605422  Warning - Loss Increasing\n",
      "Train loss:  0.23031452336207042  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923892  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314228  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.23122183859413942  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637158  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.23207162752256846  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860025  Warning - Loss Increasing\n",
      "Train loss:  0.232585595040107  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916366  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422398  Warning - Loss Increasing\n",
      "Train loss:  0.2336543234976179  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.23401783920759375  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420954  Warning - Loss Increasing\n",
      "Train loss:  0.2345518540937203  Warning - Loss Increasing\n",
      "Train loss:  0.23471662437783333  Warning - Loss Increasing\n",
      "Train loss:  0.2348870418973349  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918452  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21796458522239714\n",
      "Train loss:  0.2179500090640299\n",
      "Train loss:  0.21794007296007215\n",
      "Train loss:  0.21792649014035734\n",
      "Train loss:  0.21791360815581\n",
      "Train loss:  0.2179003989996451\n",
      "Train loss:  0.21788725638621795\n",
      "Train loss:  0.21787937752274356\n",
      "Train loss:  0.2178716546823902\n",
      "Train loss:  0.21786551938336124\n",
      "Train loss:  0.21784564713764334\n",
      "Train loss:  0.21782508020730432\n",
      "Train loss:  0.21780471418240765\n",
      "Train loss:  0.21778451237615692\n",
      "Train loss:  0.21776382591050225\n",
      "Train loss:  0.21774162144189016\n",
      "Train loss:  0.21771911558885826\n",
      "Train loss:  0.21769077222142094\n",
      "Train loss:  0.21766242135123354\n",
      "Train loss:  0.21763569263466395\n",
      "Train loss:  0.21761368568195796\n",
      "Train loss:  0.21759189988484143\n",
      "Train loss:  0.2175750892385444\n",
      "Train loss:  0.21755846262536557\n",
      "Train loss:  0.21754203042150147\n",
      "Train loss:  0.2175257851620683\n",
      "Train loss:  0.21749471754404293\n",
      "Train loss:  0.21747328483584671\n",
      "Train loss:  0.21744949363683203\n",
      "Train loss:  0.2174302109300442\n",
      "Train loss:  0.21739882900143867\n",
      "Train loss:  0.21736759735428812\n",
      "Train loss:  0.2173368558889687\n",
      "Train loss:  0.21730616543309655\n",
      "Train loss:  0.21727600524797488\n",
      "Train loss:  0.2172414908934712\n",
      "Train loss:  0.2172083728136746\n",
      "Train loss:  0.2171742531925017\n",
      "Train loss:  0.21713437894203602\n",
      "Train loss:  0.21710294761068502\n",
      "Train loss:  0.2170716917745645\n",
      "Train loss:  0.21704777025334043\n",
      "Train loss:  0.21702394827758992\n",
      "Train loss:  0.21700074975853376\n",
      "Train loss:  0.21697780739732903\n",
      "Train loss:  0.21695468281677133\n",
      "Train loss:  0.21692149761218377\n",
      "Train loss:  0.21688774296818691\n",
      "Train loss:  0.21685412432861192\n",
      "Train loss:  0.21682560898444853\n",
      "Train loss:  0.2167989787151578\n",
      "Train loss:  0.21677309250590485\n",
      "Train loss:  0.21675031972641237\n",
      "Train loss:  0.21671583161251723\n",
      "Train loss:  0.21667696391624425\n",
      "Train loss:  0.21663595367029104\n",
      "Train loss:  0.21658225717707943\n",
      "Train loss:  0.21652485186817888\n",
      "Train loss:  0.21646672214410306\n",
      "Train loss:  0.21641387272072093\n",
      "Train loss:  0.2163458573072385\n",
      "Train loss:  0.21627880009899778\n",
      "Train loss:  0.21621099441009253\n",
      "Train loss:  0.2161465310834956\n",
      "Train loss:  0.21608130869865194\n",
      "Train loss:  0.21600964848449888\n",
      "Train loss:  0.21593632136455648\n",
      "Train loss:  0.21586889219080788\n",
      "Train loss:  0.21580411677681696\n",
      "Train loss:  0.2157299583005545\n",
      "Train loss:  0.2156560418505878\n",
      "Train loss:  0.21557049486743166\n",
      "Train loss:  0.21548970949939858\n",
      "Train loss:  0.21540671168305328\n",
      "Train loss:  0.21532349700452286\n",
      "Train loss:  0.21523626181783306\n",
      "Train loss:  0.21514932169656062\n",
      "Train loss:  0.215049192515113\n",
      "Train loss:  0.21494955430295531\n",
      "Train loss:  0.2148501474189756\n",
      "Train loss:  0.21475115664804\n",
      "Train loss:  0.21463832216679019\n",
      "Train loss:  0.2145264894067235\n",
      "Train loss:  0.21441436511324213\n",
      "Train loss:  0.21430328207059396\n",
      "Train loss:  0.21420263221653132\n",
      "Train loss:  0.21409622941725684\n",
      "Train loss:  0.21399769473916982\n",
      "Train loss:  0.21389944073331416\n",
      "Train loss:  0.21378866827688894\n",
      "Train loss:  0.21367823220112703\n",
      "Train loss:  0.2135700119382114\n",
      "Train loss:  0.2134627531562208\n",
      "Train loss:  0.2133560125724631\n",
      "Train loss:  0.21324523039900004\n",
      "Train loss:  0.21313489552995782\n",
      "Train loss:  0.2130259520447546\n",
      "Train loss:  0.21290714557715873\n",
      "Train loss:  0.2127849604891746\n",
      "Train loss:  0.21264767769259527\n",
      "Train loss:  0.21251152334310022\n",
      "Train loss:  0.2123758478256539\n",
      "Train loss:  0.21222476690113842\n",
      "Train loss:  0.21206678454109265\n",
      "Train loss:  0.21190937891935163\n",
      "Train loss:  0.21175312450352227\n",
      "Train loss:  0.21159928059820254\n",
      "Train loss:  0.21143280117577967\n",
      "Train loss:  0.21126830404012245\n",
      "Train loss:  0.21110555023376848\n",
      "Train loss:  0.21094452989806128\n",
      "Train loss:  0.21078449138873379\n",
      "Train loss:  0.21061659237924948\n",
      "Train loss:  0.21045420979258672\n",
      "Train loss:  0.21029348040161\n",
      "Train loss:  0.21013364210775096\n",
      "Train loss:  0.20997641371545075\n",
      "Train loss:  0.20982031720777594\n",
      "Train loss:  0.20966526267270116\n",
      "Train loss:  0.2095114367133473\n",
      "Train loss:  0.20935657597743054\n",
      "Train loss:  0.2092036691881089\n",
      "Train loss:  0.20905196526888542\n",
      "Train loss:  0.20889760200490032\n",
      "Train loss:  0.20875032369621277\n",
      "Train loss:  0.20860609657624765\n",
      "Train loss:  0.2084625178070799\n",
      "Train loss:  0.20832224347108644\n",
      "Train loss:  0.20817490039983658\n",
      "Train loss:  0.20801361706778101\n",
      "Train loss:  0.20784801305607664\n",
      "Train loss:  0.20768434481369902\n",
      "Train loss:  0.20752287798551966\n",
      "Train loss:  0.20736318086197367\n",
      "Train loss:  0.20720533314346787\n",
      "Train loss:  0.20705104613824957\n",
      "Train loss:  0.20690364198602174\n",
      "Train loss:  0.20675805707050915\n",
      "Train loss:  0.2066168086140067\n",
      "Train loss:  0.20647661241473902\n",
      "Train loss:  0.20633913270282514\n",
      "Train loss:  0.20620471772041166\n",
      "Train loss:  0.20606996224790752\n",
      "Train loss:  0.20593496383996385\n",
      "Train loss:  0.20580171302884728\n",
      "Train loss:  0.2056661358390466\n",
      "Train loss:  0.20553251101118938\n",
      "Train loss:  0.20540084212839602\n",
      "Train loss:  0.20526425701986162\n",
      "Train loss:  0.20513044351085583\n",
      "Train loss:  0.20499483340279825\n",
      "Train loss:  0.20486151299483119\n",
      "Train loss:  0.2047280215991466\n",
      "Train loss:  0.20459768376239065\n",
      "Train loss:  0.20445832140700856\n",
      "Train loss:  0.20431969712533662\n",
      "Train loss:  0.2041832174742451\n",
      "Train loss:  0.20404994461671772\n",
      "Train loss:  0.20391559227961523\n",
      "Train loss:  0.20377939554993144\n",
      "Train loss:  0.20364644644588026\n",
      "Train loss:  0.2035169479919545\n",
      "Train loss:  0.20339228925322364\n",
      "Train loss:  0.20327076019843981\n",
      "Train loss:  0.20314931419839072\n",
      "Train loss:  0.2030351360634134\n",
      "Train loss:  0.20292738958950224\n",
      "Train loss:  0.2028232281923458\n",
      "Train loss:  0.20272231966875226\n",
      "Train loss:  0.2026252066511215\n",
      "Train loss:  0.20252347401542461\n",
      "Train loss:  0.20241991689189598\n",
      "Train loss:  0.202320403365577\n",
      "Train loss:  0.20222443640575272\n",
      "Train loss:  0.20213254281528775\n",
      "Train loss:  0.20204375053447893\n",
      "Train loss:  0.20195969929619093\n",
      "Train loss:  0.2018798155638055\n",
      "Train loss:  0.20180267485484266\n",
      "Train loss:  0.2017295549838306\n",
      "Train loss:  0.20166081505543637\n",
      "Train loss:  0.20159635833188053\n",
      "Train loss:  0.20153628837881865\n",
      "Train loss:  0.2014780971413834\n",
      "Train loss:  0.20142359176527333\n",
      "Train loss:  0.20137392590909048\n",
      "Train loss:  0.20132914655562514\n",
      "Train loss:  0.20128804235829298\n",
      "Train loss:  0.20125457466713176\n",
      "Train loss:  0.20122595997396583\n",
      "Train loss:  0.20120178693269344\n",
      "Train loss:  0.2011825395568423\n",
      "Train loss:  0.2011676640067608\n",
      "Train loss:  0.20115720609687046\n",
      "Train loss:  0.20115094476625145\n",
      "Train loss:  0.20114880368791302\n",
      "Train loss:  0.20115069343582148  Warning - Loss Increasing\n",
      "Train loss:  0.20115454003685018  Warning - Loss Increasing\n",
      "Train loss:  0.20116060067566555  Warning - Loss Increasing\n",
      "Train loss:  0.2011689247294021  Warning - Loss Increasing\n",
      "Train loss:  0.20117890674119754  Warning - Loss Increasing\n",
      "Train loss:  0.20119297755309762  Warning - Loss Increasing\n",
      "Train loss:  0.2012109801595887  Warning - Loss Increasing\n",
      "Train loss:  0.20123304977489018  Warning - Loss Increasing\n",
      "Train loss:  0.20125902326185646  Warning - Loss Increasing\n",
      "Train loss:  0.201288912335922  Warning - Loss Increasing\n",
      "Train loss:  0.20132185974477929  Warning - Loss Increasing\n",
      "Train loss:  0.20135827609396947  Warning - Loss Increasing\n",
      "Train loss:  0.20139934944230392  Warning - Loss Increasing\n",
      "Train loss:  0.20144629947812903  Warning - Loss Increasing\n",
      "Train loss:  0.20149979977327084  Warning - Loss Increasing\n",
      "Train loss:  0.2015581631508242  Warning - Loss Increasing\n",
      "Train loss:  0.2016213698221258  Warning - Loss Increasing\n",
      "Train loss:  0.20168742137266252  Warning - Loss Increasing\n",
      "Train loss:  0.20175874785298936  Warning - Loss Increasing\n",
      "Train loss:  0.20183740436509542  Warning - Loss Increasing\n",
      "Train loss:  0.2019235912146183  Warning - Loss Increasing\n",
      "Train loss:  0.20201493629172707  Warning - Loss Increasing\n",
      "Train loss:  0.2021140257646486  Warning - Loss Increasing\n",
      "Train loss:  0.20221654107085307  Warning - Loss Increasing\n",
      "Train loss:  0.20232490527873354  Warning - Loss Increasing\n",
      "Train loss:  0.20243914541754376  Warning - Loss Increasing\n",
      "Train loss:  0.20255813121892707  Warning - Loss Increasing\n",
      "Train loss:  0.20268248338453665  Warning - Loss Increasing\n",
      "Train loss:  0.2028129840008768  Warning - Loss Increasing\n",
      "Train loss:  0.20294928253971187  Warning - Loss Increasing\n",
      "Train loss:  0.2030923556805358  Warning - Loss Increasing\n",
      "Train loss:  0.2032396871937267  Warning - Loss Increasing\n",
      "Train loss:  0.2033903262224276  Warning - Loss Increasing\n",
      "Train loss:  0.203544051454233  Warning - Loss Increasing\n",
      "Train loss:  0.20370437291044954  Warning - Loss Increasing\n",
      "Train loss:  0.20386839413316565  Warning - Loss Increasing\n",
      "Train loss:  0.2040393679491652  Warning - Loss Increasing\n",
      "Train loss:  0.20421420275652555  Warning - Loss Increasing\n",
      "Train loss:  0.2043897429708384  Warning - Loss Increasing\n",
      "Train loss:  0.20457103007826719  Warning - Loss Increasing\n",
      "Train loss:  0.2047581079984446  Warning - Loss Increasing\n",
      "Train loss:  0.20494714755585058  Warning - Loss Increasing\n",
      "Train loss:  0.20514105908423505  Warning - Loss Increasing\n",
      "Train loss:  0.2053271265345308  Warning - Loss Increasing\n",
      "Train loss:  0.20551562938055945  Warning - Loss Increasing\n",
      "Train loss:  0.205709776655798  Warning - Loss Increasing\n",
      "Train loss:  0.20590884182193092  Warning - Loss Increasing\n",
      "Train loss:  0.2061116892876619  Warning - Loss Increasing\n",
      "Train loss:  0.2063154947135426  Warning - Loss Increasing\n",
      "Train loss:  0.2065228357407975  Warning - Loss Increasing\n",
      "Train loss:  0.20673643305426787  Warning - Loss Increasing\n",
      "Train loss:  0.20695306284880083  Warning - Loss Increasing\n",
      "Train loss:  0.20717484531088817  Warning - Loss Increasing\n",
      "Train loss:  0.2073965222083277  Warning - Loss Increasing\n",
      "Train loss:  0.20762158149309667  Warning - Loss Increasing\n",
      "Train loss:  0.2078442845273403  Warning - Loss Increasing\n",
      "Train loss:  0.20806977850761071  Warning - Loss Increasing\n",
      "Train loss:  0.20829460581051626  Warning - Loss Increasing\n",
      "Train loss:  0.2085229387130932  Warning - Loss Increasing\n",
      "Train loss:  0.20875561567322873  Warning - Loss Increasing\n",
      "Train loss:  0.20899393494232976  Warning - Loss Increasing\n",
      "Train loss:  0.20923392792180265  Warning - Loss Increasing\n",
      "Train loss:  0.20947843731653334  Warning - Loss Increasing\n",
      "Train loss:  0.20972687934066403  Warning - Loss Increasing\n",
      "Train loss:  0.20998060441981753  Warning - Loss Increasing\n",
      "Train loss:  0.2102286408958241  Warning - Loss Increasing\n",
      "Train loss:  0.21047715922829516  Warning - Loss Increasing\n",
      "Train loss:  0.21072152783266315  Warning - Loss Increasing\n",
      "Train loss:  0.2109684739432716  Warning - Loss Increasing\n",
      "Train loss:  0.2112192794620252  Warning - Loss Increasing\n",
      "Train loss:  0.21147225600086392  Warning - Loss Increasing\n",
      "Train loss:  0.21171757825179488  Warning - Loss Increasing\n",
      "Train loss:  0.21196742167281102  Warning - Loss Increasing\n",
      "Train loss:  0.2122218023811839  Warning - Loss Increasing\n",
      "Train loss:  0.2124779753438703  Warning - Loss Increasing\n",
      "Train loss:  0.21273172103718999  Warning - Loss Increasing\n",
      "Train loss:  0.212988841435576  Warning - Loss Increasing\n",
      "Train loss:  0.21324610359551022  Warning - Loss Increasing\n",
      "Train loss:  0.21350610839307638  Warning - Loss Increasing\n",
      "Train loss:  0.2137674974960811  Warning - Loss Increasing\n",
      "Train loss:  0.21403239745761454  Warning - Loss Increasing\n",
      "Train loss:  0.21430852043575577  Warning - Loss Increasing\n",
      "Train loss:  0.21458067532898448  Warning - Loss Increasing\n",
      "Train loss:  0.21485642332647528  Warning - Loss Increasing\n",
      "Train loss:  0.21513334526440073  Warning - Loss Increasing\n",
      "Train loss:  0.21541493025003797  Warning - Loss Increasing\n",
      "Train loss:  0.21569532938968122  Warning - Loss Increasing\n",
      "Train loss:  0.21597648440678247  Warning - Loss Increasing\n",
      "Train loss:  0.216262743836462  Warning - Loss Increasing\n",
      "Train loss:  0.21656303207865513  Warning - Loss Increasing\n",
      "Train loss:  0.2168666419804908  Warning - Loss Increasing\n",
      "Train loss:  0.2171709721203034  Warning - Loss Increasing\n",
      "Train loss:  0.2174774075867011  Warning - Loss Increasing\n",
      "Train loss:  0.21778995414672014  Warning - Loss Increasing\n",
      "Train loss:  0.21810504588036395  Warning - Loss Increasing\n",
      "Train loss:  0.21842117220550575  Warning - Loss Increasing\n",
      "Train loss:  0.2187403509230077  Warning - Loss Increasing\n",
      "Train loss:  0.21905755851884393  Warning - Loss Increasing\n",
      "Train loss:  0.2193789278438075  Warning - Loss Increasing\n",
      "Train loss:  0.2197053509197566  Warning - Loss Increasing\n",
      "Train loss:  0.22003228293377933  Warning - Loss Increasing\n",
      "Train loss:  0.22036312755717266  Warning - Loss Increasing\n",
      "Train loss:  0.220696468446787  Warning - Loss Increasing\n",
      "Train loss:  0.22103332361615272  Warning - Loss Increasing\n",
      "Train loss:  0.22137377970790412  Warning - Loss Increasing\n",
      "Train loss:  0.2217051470537912  Warning - Loss Increasing\n",
      "Train loss:  0.22203190391688124  Warning - Loss Increasing\n",
      "Train loss:  0.22236278240747756  Warning - Loss Increasing\n",
      "Train loss:  0.22269717657265117  Warning - Loss Increasing\n",
      "Train loss:  0.22303413468312375  Warning - Loss Increasing\n",
      "Train loss:  0.2233716544418349  Warning - Loss Increasing\n",
      "Train loss:  0.22371299410900924  Warning - Loss Increasing\n",
      "Train loss:  0.22405785674125234  Warning - Loss Increasing\n",
      "Train loss:  0.2244065852634699  Warning - Loss Increasing\n",
      "Train loss:  0.22473865539591648  Warning - Loss Increasing\n",
      "Train loss:  0.22506084159091055  Warning - Loss Increasing\n",
      "Train loss:  0.2253705915049094  Warning - Loss Increasing\n",
      "Train loss:  0.2256781715106563  Warning - Loss Increasing\n",
      "Train loss:  0.22597144710527553  Warning - Loss Increasing\n",
      "Train loss:  0.22623887331433465  Warning - Loss Increasing\n",
      "Train loss:  0.22650637331955978  Warning - Loss Increasing\n",
      "Train loss:  0.2267759469936467  Warning - Loss Increasing\n",
      "Train loss:  0.22703799808500955  Warning - Loss Increasing\n",
      "Train loss:  0.22729368170556244  Warning - Loss Increasing\n",
      "Train loss:  0.2275395536722771  Warning - Loss Increasing\n",
      "Train loss:  0.22778534257747313  Warning - Loss Increasing\n",
      "Train loss:  0.22803386206014192  Warning - Loss Increasing\n",
      "Train loss:  0.22828315095891785  Warning - Loss Increasing\n",
      "Train loss:  0.2285251075742673  Warning - Loss Increasing\n",
      "Train loss:  0.22876195226589502  Warning - Loss Increasing\n",
      "Train loss:  0.22898170807375984  Warning - Loss Increasing\n",
      "Train loss:  0.22919700653621763  Warning - Loss Increasing\n",
      "Train loss:  0.2294159439267489  Warning - Loss Increasing\n",
      "Train loss:  0.2296380148314247  Warning - Loss Increasing\n",
      "Train loss:  0.22985969639344586  Warning - Loss Increasing\n",
      "Train loss:  0.23008410986054223  Warning - Loss Increasing\n",
      "Train loss:  0.2303145233620706  Warning - Loss Increasing\n",
      "Train loss:  0.23054049457923895  Warning - Loss Increasing\n",
      "Train loss:  0.23077041280314223  Warning - Loss Increasing\n",
      "Train loss:  0.2309985053336219  Warning - Loss Increasing\n",
      "Train loss:  0.2312218385941395  Warning - Loss Increasing\n",
      "Train loss:  0.23143844927637164  Warning - Loss Increasing\n",
      "Train loss:  0.23165303407246335  Warning - Loss Increasing\n",
      "Train loss:  0.23186772912592027  Warning - Loss Increasing\n",
      "Train loss:  0.2320716275225684  Warning - Loss Increasing\n",
      "Train loss:  0.2322533146659493  Warning - Loss Increasing\n",
      "Train loss:  0.23242671349860022  Warning - Loss Increasing\n",
      "Train loss:  0.2325855950401071  Warning - Loss Increasing\n",
      "Train loss:  0.2327397036916367  Warning - Loss Increasing\n",
      "Train loss:  0.23289493421002194  Warning - Loss Increasing\n",
      "Train loss:  0.2330469734460044  Warning - Loss Increasing\n",
      "Train loss:  0.23319422504480122  Warning - Loss Increasing\n",
      "Train loss:  0.23333680908557738  Warning - Loss Increasing\n",
      "Train loss:  0.23348058743422395  Warning - Loss Increasing\n",
      "Train loss:  0.233654323497618  Warning - Loss Increasing\n",
      "Train loss:  0.2338339773832765  Warning - Loss Increasing\n",
      "Train loss:  0.2340178392075937  Warning - Loss Increasing\n",
      "Train loss:  0.23419922431911241  Warning - Loss Increasing\n",
      "Train loss:  0.23438119172420957  Warning - Loss Increasing\n",
      "Train loss:  0.23455185409372037  Warning - Loss Increasing\n",
      "Train loss:  0.2347166243778333  Warning - Loss Increasing\n",
      "Train loss:  0.23488704189733486  Warning - Loss Increasing\n",
      "Train loss:  0.2350723459017477  Warning - Loss Increasing\n",
      "Train loss:  0.23525191767918463  Warning - Loss Increasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicition accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape #360,6\n",
    "last_loss = None\n",
    "\n",
    "# initialize weights\n",
    "weights = np.random.normal(scale=1/n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network Hyper permeters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        output = sigmoid(np.dot(x,weights))\n",
    "        \n",
    "        error = y - output\n",
    "        error_term = error * output * (1-output)\n",
    "        \n",
    "        del_w += error_term * x\n",
    "        \n",
    "        weights += learnrate * del_w / n_records\n",
    "        \n",
    "        if e % (epochs/10) == 0:\n",
    "            out = sigmoid( np.dot(features, weights))\n",
    "            loss = np.mean( (out - targets)**2 )\n",
    "            \n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \" Warning - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "                \n",
    "            last_loss = loss\n",
    "\n",
    "# calculate accuracy on test data\n",
    "test_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Predicition accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24119422, 0.1532274 , 0.05763573, 0.10564512, 0.34694017,\n",
       "       0.14087972, 0.21995636, 0.22115312, 0.15836779, 0.5309982 ,\n",
       "       0.14493056, 0.57306524, 0.17311452, 0.16264118, 0.25806822,\n",
       "       0.29473878, 0.15388083, 0.20640595, 0.15081121, 0.72476217,\n",
       "       0.05763573, 0.16491463, 0.16037466, 0.16135963, 0.17268866,\n",
       "       0.19332504, 0.07704496, 0.10185169, 0.18538634, 0.15206189,\n",
       "       0.1570777 , 0.16654364, 0.36848651, 0.27628718, 0.34959797,\n",
       "       0.308094  , 0.60168814, 0.10110173, 0.21349022, 0.09843159,\n",
       "       0.25851688, 0.06482224, 0.15227091, 0.4010278 , 0.43354732,\n",
       "       0.25507737, 0.71953731, 0.10698014, 0.20174848, 0.17624599,\n",
       "       0.24785237, 0.27529755, 0.63545409, 0.07867513, 0.20477214,\n",
       "       0.26488893, 0.08975205, 0.11151541, 0.10761895, 0.15871923,\n",
       "       0.07452066, 0.78015393, 0.13299068, 0.65198485, 0.12478784,\n",
       "       0.1066817 , 0.176193  , 0.2110344 , 0.11145241, 0.16844428,\n",
       "       0.21247754, 0.15992615, 0.25519824, 0.16946881, 0.27409553,\n",
       "       0.22960028, 0.19302693, 0.12384663, 0.44324218, 0.37864535,\n",
       "       0.14279711, 0.13819739, 0.377786  , 0.12541708, 0.33658187,\n",
       "       0.08250702, 0.0980103 , 0.10510316, 0.26979492, 0.15527295,\n",
       "       0.30936327, 0.48231852, 0.39240157, 0.16754999, 0.09792258,\n",
       "       0.13860267, 0.55863363, 0.17775518, 0.11006846, 0.06739774,\n",
       "       0.36430274, 0.14472722, 0.06314819, 0.08406731, 0.13602205,\n",
       "       0.40318845, 0.50150409, 0.07006789, 0.61020913, 0.34437241,\n",
       "       0.34716511, 0.26502948, 0.17726833, 0.14132808, 0.37558095,\n",
       "       0.2806515 , 0.41773598, 0.13980134, 0.12893755, 0.22818356,\n",
       "       0.58380928, 0.29059705, 0.35920521, 0.19521505, 0.19997312,\n",
       "       0.24741605, 0.12952804, 0.73541531, 0.08165168, 0.06220184,\n",
       "       0.18751904, 0.19710414, 0.26308547, 0.15123875, 0.29702794,\n",
       "       0.23851636, 0.20325093, 0.21025421, 0.71520735, 0.23954888,\n",
       "       0.60520281, 0.52201277, 0.27762435, 0.2026642 , 0.15920126,\n",
       "       0.31973733, 0.20174848, 0.17776455, 0.377786  , 0.30116537,\n",
       "       0.67088906, 0.14430599, 0.32754895, 0.38384199, 0.05437692,\n",
       "       0.09584906, 0.09994666, 0.30109031, 0.45141677, 0.17775518,\n",
       "       0.13059615, 0.18317851, 0.49882488, 0.10262038, 0.19552714,\n",
       "       0.14634315, 0.11348592, 0.41893787, 0.2439425 , 0.29432627,\n",
       "       0.12287217, 0.38597538, 0.22281778, 0.11011051, 0.14250182,\n",
       "       0.2344169 , 0.26881992, 0.23096972, 0.50767627, 0.13288463,\n",
       "       0.22812076, 0.13513263, 0.23615113, 0.13622364, 0.5741236 ,\n",
       "       0.11469683, 0.26139453, 0.2340608 , 0.07721682, 0.2340608 ,\n",
       "       0.14743569, 0.29997202, 0.08885773, 0.26392524, 0.19089148,\n",
       "       0.17708098, 0.15970571, 0.21164963, 0.14671451, 0.38810748,\n",
       "       0.20276911, 0.1201376 , 0.18834069, 0.32880047, 0.11222065,\n",
       "       0.2008931 , 0.34392431, 0.67836488, 0.40923573, 0.15509606,\n",
       "       0.69910649, 0.27382548, 0.29751717, 0.25229662, 0.11039552,\n",
       "       0.16872255, 0.43815987, 0.53241161, 0.46391953, 0.09166012,\n",
       "       0.26301633, 0.27569381, 0.12920081, 0.14785533, 0.10532364,\n",
       "       0.10067686, 0.20954861, 0.13963045, 0.33013856, 0.45233693,\n",
       "       0.08243191, 0.42946324, 0.19971269, 0.50483849, 0.22491573,\n",
       "       0.52025948, 0.25646792, 0.46917112, 0.15875542, 0.11775145,\n",
       "       0.41536684, 0.07610693, 0.10034315, 0.20783772, 0.62628424,\n",
       "       0.26941827, 0.21749649, 0.35339844, 0.09821753, 0.63413812,\n",
       "       0.20760372, 0.66815747, 0.24236319, 0.23423881, 0.29072818,\n",
       "       0.1105281 , 0.21943486, 0.36530544, 0.16703579, 0.12540912,\n",
       "       0.08140199, 0.34884557, 0.40971   , 0.21231289, 0.17971181,\n",
       "       0.081185  , 0.12707655, 0.18124539, 0.07344644, 0.2386967 ,\n",
       "       0.2106554 , 0.45331482, 0.25679336, 0.37050073, 0.14003152,\n",
       "       0.27210964, 0.09165408, 0.45812554, 0.0912709 , 0.10595373,\n",
       "       0.21288183, 0.30137432, 0.11771353, 0.25564203, 0.21388372,\n",
       "       0.25405162, 0.12990447, 0.23512872, 0.30200169, 0.17946047,\n",
       "       0.14899427, 0.21383454, 0.13747942, 0.11378502, 0.10224822,\n",
       "       0.23339971, 0.11531827, 0.09154181, 0.14714156, 0.26828984,\n",
       "       0.11007557, 0.1899197 , 0.21315706, 0.24241691, 0.10311132,\n",
       "       0.14418346, 0.31359587, 0.15417653, 0.08823937, 0.25141408,\n",
       "       0.377786  , 0.44488858, 0.46723826, 0.24585835, 0.47938948,\n",
       "       0.77612432, 0.27118293, 0.2587072 , 0.21349022, 0.48990441,\n",
       "       0.41869625, 0.17735988, 0.59140845, 0.14572257, 0.23155113,\n",
       "       0.26359234, 0.14340732, 0.25046505, 0.29404611, 0.219034  ,\n",
       "       0.17556579, 0.58080654, 0.31719584, 0.24524061, 0.17499304,\n",
       "       0.26848475, 0.24094737, 0.09931642, 0.20195417, 0.16028727,\n",
       "       0.07094199, 0.72814619, 0.08519952, 0.44613963, 0.1166418 ,\n",
       "       0.10311803, 0.21511313, 0.10716301, 0.51193195, 0.26541637,\n",
       "       0.5081665 , 0.53738901, 0.54914894, 0.19464585, 0.26855479,\n",
       "       0.18925486, 0.35232889, 0.64169312, 0.3975904 , 0.61859745])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
